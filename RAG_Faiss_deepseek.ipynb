{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684cb521-ba2c-43e2-a349-3acd347a391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus==2.5.10 in e:\\anaconda\\lib\\site-packages (from pymilvus[model]==2.5.10) (2.5.10)\n",
      "Requirement already satisfied: openai==1.82.0 in e:\\anaconda\\lib\\site-packages (1.82.0)\n",
      "Requirement already satisfied: requests==2.32.3 in e:\\anaconda\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: tqdm==4.67.1 in e:\\anaconda\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: torch==2.7.0 in e:\\anaconda\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: setuptools>69 in e:\\anaconda\\lib\\site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (72.1.0)\n",
      "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in e:\\anaconda\\lib\\site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (1.67.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in e:\\anaconda\\lib\\site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (5.29.3)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in e:\\anaconda\\lib\\site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (1.1.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in e:\\anaconda\\lib\\site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in e:\\anaconda\\lib\\site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (2.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\anaconda\\lib\\site-packages (from openai==1.82.0) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\anaconda\\lib\\site-packages (from openai==1.82.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\anaconda\\lib\\site-packages (from openai==1.82.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\anaconda\\lib\\site-packages (from openai==1.82.0) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\anaconda\\lib\\site-packages (from openai==1.82.0) (2.10.3)\n",
      "Requirement already satisfied: sniffio in e:\\anaconda\\lib\\site-packages (from openai==1.82.0) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in e:\\anaconda\\lib\\site-packages (from openai==1.82.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests==2.32.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests==2.32.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests==2.32.3) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests==2.32.3) (2025.4.26)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm==4.67.1) (0.4.6)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\lib\\site-packages (from torch==2.7.0) (3.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\anaconda\\lib\\site-packages (from torch==2.7.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in e:\\anaconda\\lib\\site-packages (from torch==2.7.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from torch==2.7.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\anaconda\\lib\\site-packages (from torch==2.7.0) (2025.3.2)\n",
      "Requirement already satisfied: pymilvus.model>=0.3.0 in e:\\anaconda\\lib\\site-packages (from pymilvus[model]==2.5.10) (0.3.2)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.82.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.82.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.82.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in e:\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.82.0) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\anaconda\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (2025.2)\n",
      "Requirement already satisfied: transformers>=4.36.0 in e:\\anaconda\\lib\\site-packages (from pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (4.56.0)\n",
      "Requirement already satisfied: onnxruntime in e:\\anaconda\\lib\\site-packages (from pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (1.22.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in e:\\anaconda\\lib\\site-packages (from pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (1.15.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\anaconda\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in e:\\anaconda\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\anaconda\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\anaconda\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\anaconda\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\anaconda\\lib\\site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (0.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from jinja2->torch==2.7.0) (3.0.2)\n",
      "Requirement already satisfied: coloredlogs in e:\\anaconda\\lib\\site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in e:\\anaconda\\lib\\site-packages (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (25.2.10)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in e:\\anaconda\\lib\\site-packages (from coloredlogs->onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in e:\\anaconda\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (3.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"pymilvus[model]==2.5.10\" openai==1.82.0 requests==2.32.3 tqdm==4.67.1 torch==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f26d991-5842-4778-82f2-d3d1b975f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-e7f0cd5b1a7a4d9f93e29f00a8145705\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ä»ç¯å¢ƒå˜é‡è·å– DeepSeek API Key\n",
    "api_key = \"sk-e7f0cd5b1a7a4d9f93e29f00a8145705\"\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a1bcaf-f219-4b5b-b2e5-21b5ca99d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_lines = []\n",
    "\n",
    "for file_path in glob(\"milvus_docs_2.4.x_en/en/faq/*.md\", recursive=True):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_text = file.read()\n",
    "\n",
    "    text_lines += file_text.split(\"# \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1557ac4-3b1b-4c05-b763-71349e809071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0404045-7883-4158-a0a4-86c63e8d0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "deepseek_client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://api.deepseek.com/v1\",  # DeepSeek API çš„åŸºåœ°å€\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7816495d-7e45-4d2e-8bfc-6afde60b8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_lines = []\n",
    "\n",
    "for file_path in glob(\"milvus_docs_2.4.x_en/en/faq/*.md\", recursive=True):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_text = file.read()\n",
    "\n",
    "    text_lines += file_text.split(\"# \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449ca844-8b32-45af-943f-b84ddb047743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "203652f6-8f95-446e-a1d6-3c03d65a38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operational FAQ\n",
      "\n",
      "<!-- TOC -->\n",
      "\n",
      "\n",
      "<!-- /TOC -->\n",
      "\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "print(text_lines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17dabea-a72d-4681-8f01-8030919d9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "deepseek_client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://api.deepseek.com/v1\",  # DeepSeek API çš„åŸºåœ°å€\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac88542-e9ce-4d5f-9ca7-b2bea20535cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import model as milvus_model\n",
    "\n",
    "embedding_model = milvus_model.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a21b4b-4b3b-425e-8f70-af6702045da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "[-0.04836059  0.07163021 -0.01130063 -0.03789341 -0.03320651 -0.01318453\n",
      " -0.03041721 -0.02269495 -0.02317858 -0.00426026]\n"
     ]
    }
   ],
   "source": [
    "test_embedding = embedding_model.encode_queries([\"This is a test\"])[0]\n",
    "embedding_dim = len(test_embedding)\n",
    "print(embedding_dim)\n",
    "print(test_embedding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b565e57-f70e-464c-83c9-7dd1e65ce1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02752976  0.0608853   0.00388525 -0.00215193 -0.02774976 -0.0118618\n",
      " -0.04020916 -0.06023417 -0.03813156  0.0100272 ]\n"
     ]
    }
   ],
   "source": [
    "test_embedding_0 = embedding_model.encode_queries([\"That is a test\"])[0]\n",
    "print(test_embedding_0[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4896c2cd-4065-4c7e-b68f-4181f82b3da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in e:\\anaconda\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in e:\\anaconda\\lib\\site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84e2ba61-0192-4a39-9237-1cb9df3b21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ£€æŸ¥é›†åˆ my_rag_collection æ˜¯å¦å­˜åœ¨ï¼šå¦\n",
      "ğŸ” æ£€æŸ¥é›†åˆ my_rag_collection æ˜¯å¦å­˜åœ¨ï¼šå¦\n",
      "âœ… é›†åˆ my_rag_collection åˆ›å»ºæˆåŠŸ\n",
      "âœ… å‘é›†åˆæ’å…¥ 3 æ¡æ•°æ®æˆåŠŸ\n",
      "\n",
      "ğŸ“Š æ£€ç´¢åˆ°çš„ç›¸ä¼¼æ–‡æœ¬ï¼š\n",
      "1. æ–‡æœ¬1ï¼šæœºå™¨å­¦ä¹ åŸºç¡€\n",
      "2. æ–‡æœ¬2ï¼šæ·±åº¦å­¦ä¹ å®æˆ˜\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "class FaissVectorStore:\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim  # å‘é‡ç»´åº¦\n",
    "        self.index = faiss.IndexFlatL2(dim)  # FAISS ç´¢å¼•\n",
    "        self.vectors = []  # å­˜å‚¨åŸå§‹å‘é‡\n",
    "        self.texts = []    # å­˜å‚¨å‘é‡å¯¹åº”æ–‡æœ¬\n",
    "        self.collection_exists = False  # æ ‡è®°é›†åˆæ˜¯å¦å­˜åœ¨ï¼ˆæ ¸å¿ƒï¼šæ›¿ä»£ Milvus çš„é›†åˆå­˜åœ¨åˆ¤æ–­ï¼‰\n",
    "\n",
    "    def has_collection(self, collection_name):\n",
    "        \"\"\"åˆ¤æ–­é›†åˆæ˜¯å¦å­˜åœ¨ï¼ˆå¯¹åº” Milvus çš„ has_collectionï¼‰\"\"\"\n",
    "        # è¿™é‡Œé  self.collection_exists æ ‡è®°ï¼Œå®é™…é¡¹ç›®å¯æŒ‰éœ€æ±‚æ‰©å±•ï¼ˆå¦‚å¤šé›†åˆç®¡ç†ï¼‰\n",
    "        print(f\"ğŸ” æ£€æŸ¥é›†åˆ {collection_name} æ˜¯å¦å­˜åœ¨ï¼š{'æ˜¯' if self.collection_exists else 'å¦'}\")\n",
    "        return self.collection_exists\n",
    "\n",
    "    def drop_collection(self, collection_name):\n",
    "        \"\"\"åˆ é™¤é›†åˆï¼ˆå¯¹åº” Milvus çš„ drop_collectionï¼‰\"\"\"\n",
    "        if self.collection_exists:\n",
    "            # æ¸…ç©ºç´¢å¼•å’Œæ•°æ®ï¼Œé‡ç½®é›†åˆçŠ¶æ€\n",
    "            self.index = faiss.IndexFlatL2(self.dim)\n",
    "            self.vectors = []\n",
    "            self.texts = []\n",
    "            self.collection_exists = False\n",
    "            print(f\"ğŸ—‘ï¸  é›†åˆ {collection_name} å·²åˆ é™¤\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤\")\n",
    "\n",
    "    def create_collection(self, collection_name):\n",
    "        \"\"\"åˆ›å»ºé›†åˆï¼ˆå¯¹åº” Milvus çš„ create_collectionï¼‰\"\"\"\n",
    "        # å…ˆåˆ¤æ–­é›†åˆæ˜¯å¦å­˜åœ¨ï¼Œå­˜åœ¨åˆ™åˆ é™¤ï¼ˆå¯¹åº”ä½ åŸæœ¬çš„é€»è¾‘ï¼‰\n",
    "        if self.has_collection(collection_name):\n",
    "            self.drop_collection(collection_name)\n",
    "        # æ ‡è®°é›†åˆä¸ºå­˜åœ¨çŠ¶æ€\n",
    "        self.collection_exists = True\n",
    "        print(f\"âœ… é›†åˆ {collection_name} åˆ›å»ºæˆåŠŸ\")\n",
    "        return True\n",
    "\n",
    "    def insert(self, vectors, texts):\n",
    "        \"\"\"æ’å…¥å‘é‡ï¼ˆå¯¹åº” Milvus çš„ insertï¼‰\"\"\"\n",
    "        if not self.collection_exists:\n",
    "            raise ValueError(\"âŒ è¯·å…ˆåˆ›å»ºé›†åˆå†æ’å…¥æ•°æ®ï¼\")\n",
    "        vectors = np.array(vectors, dtype=np.float32)\n",
    "        self.index.add(vectors)\n",
    "        self.vectors.extend(vectors)\n",
    "        self.texts.extend(texts)\n",
    "        print(f\"âœ… å‘é›†åˆæ’å…¥ {len(vectors)} æ¡æ•°æ®æˆåŠŸ\")\n",
    "        return len(vectors)\n",
    "\n",
    "    def search(self, query_vector, top_k=3):\n",
    "        \"\"\"æ£€ç´¢ç›¸ä¼¼å‘é‡ï¼ˆå¯¹åº” Milvus çš„ searchï¼‰\"\"\"\n",
    "        if not self.collection_exists:\n",
    "            raise ValueError(\"âŒ è¯·å…ˆåˆ›å»ºé›†åˆå†æ£€ç´¢æ•°æ®ï¼\")\n",
    "        query_vector = np.array([query_vector], dtype=np.float32)\n",
    "        distances, indices = self.index.search(query_vector, top_k)\n",
    "        similar_texts = [self.texts[i] for i in indices[0] if i < len(self.texts)]\n",
    "        return similar_texts\n",
    "\n",
    "# ------------------- æµ‹è¯•ï¼šå®Œå…¨å¤ç°ä½ åŸæœ¬çš„ Milvus é€»è¾‘ -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨ï¼ˆå‡è®¾æ–‡æœ¬åµŒå…¥ç»´åº¦ä¸º 3ï¼Œå®é™…ç”¨ 768ï¼‰\n",
    "    vector_store = FaissVectorStore(dim=3)\n",
    "    collection_name = \"my_rag_collection\"\n",
    "\n",
    "    # 2. æ ¸å¿ƒé€»è¾‘ï¼šåˆ¤æ–­é›†åˆæ˜¯å¦å­˜åœ¨ â†’ å­˜åœ¨åˆ™åˆ é™¤ â†’ åˆ›å»ºæ–°é›†åˆï¼ˆå’Œä½ åŸæœ¬ä»£ç ä¸€è‡´ï¼‰\n",
    "    if vector_store.has_collection(collection_name):\n",
    "        vector_store.drop_collection(collection_name)\n",
    "    vector_store.create_collection(collection_name)\n",
    "\n",
    "    # 3. æ’å…¥æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ–‡æœ¬åµŒå…¥åçš„å‘é‡ï¼‰\n",
    "    test_vectors = [\n",
    "        [0.1, 0.2, 0.3],\n",
    "        [0.4, 0.5, 0.6],\n",
    "        [0.7, 0.8, 0.9]\n",
    "    ]\n",
    "    test_texts = [\n",
    "        \"æ–‡æœ¬1ï¼šæœºå™¨å­¦ä¹ åŸºç¡€\",\n",
    "        \"æ–‡æœ¬2ï¼šæ·±åº¦å­¦ä¹ å®æˆ˜\",\n",
    "        \"æ–‡æœ¬3ï¼šå‘é‡æ•°æ®åº“åŸç†\"\n",
    "    ]\n",
    "    vector_store.insert(test_vectors, test_texts)\n",
    "\n",
    "    # 4. æ£€ç´¢ç›¸ä¼¼æ–‡æœ¬ï¼ˆæ¨¡æ‹Ÿ RAG æŸ¥è¯¢ï¼‰\n",
    "    query_vector = [0.15, 0.25, 0.35]  # æ¨¡æ‹Ÿé—®é¢˜åµŒå…¥å‘é‡\n",
    "    similar_texts = vector_store.search(query_vector, top_k=2)\n",
    "    print(\"\\nğŸ“Š æ£€ç´¢åˆ°çš„ç›¸ä¼¼æ–‡æœ¬ï¼š\")\n",
    "    for i, text in enumerate(similar_texts, 1):\n",
    "        print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f331d37a-7044-440c-b436-19f058c5ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ£€æŸ¥é›†åˆ my_rag_collection æ˜¯å¦å­˜åœ¨ï¼šå¦\n",
      "âœ… é›†åˆ my_rag_collection åˆ›å»ºæˆåŠŸ\n",
      "  - å‘é‡ç»´åº¦ï¼š768\n",
      "  - è·ç¦»ç±»å‹ï¼šIPï¼ˆå†…ç§¯ï¼‰\n",
      "  - è¯´æ˜ï¼šFaiss æœ¬åœ°ç´¢å¼•æ— éœ€ 'consistency_level' é…ç½®ï¼ŒStrong ä»…ä½œå…¼å®¹ä¿ç•™\n",
      "âœ… å‘é›†åˆ my_rag_collection æ’å…¥ 5 æ¡æ•°æ®æˆåŠŸ\n",
      "\n",
      "ğŸ“Š æ£€ç´¢åˆ°çš„ç›¸ä¼¼æ–‡æœ¬ï¼ˆtop 2ï¼‰ï¼š\n",
      "1. æ–‡æœ¬3ï¼šRAG ç¤ºä¾‹å†…å®¹\n",
      "2. æ–‡æœ¬4ï¼šRAG ç¤ºä¾‹å†…å®¹\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "class FaissVectorStore:\n",
    "    def __init__(self):\n",
    "        self.index = None  # åˆå§‹åŒ–ç´¢å¼•ä¸ºNoneï¼ˆæœªåˆ›å»ºé›†åˆæ—¶æ— ç´¢å¼•ï¼‰\n",
    "        self.vectors = []  # å­˜å‚¨åŸå§‹å‘é‡\n",
    "        self.texts = []    # å­˜å‚¨å‘é‡å¯¹åº”æ–‡æœ¬\n",
    "        self.collection_exists = False  # æ ‡è®°é›†åˆæ˜¯å¦å­˜åœ¨\n",
    "\n",
    "    def has_collection(self, collection_name):\n",
    "        print(f\"ğŸ” æ£€æŸ¥é›†åˆ {collection_name} æ˜¯å¦å­˜åœ¨ï¼š{'æ˜¯' if self.collection_exists else 'å¦'}\")\n",
    "        return self.collection_exists\n",
    "\n",
    "    def drop_collection(self, collection_name):\n",
    "        if self.collection_exists:\n",
    "            self.index = None  # æ¸…ç©ºç´¢å¼•\n",
    "            self.vectors = []\n",
    "            self.texts = []\n",
    "            self.collection_exists = False\n",
    "            print(f\"ğŸ—‘ï¸  é›†åˆ {collection_name} å·²åˆ é™¤\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤\")\n",
    "\n",
    "    # ------------------- æ ¸å¿ƒä¿®æ”¹ï¼šé€‚é… Faiss çš„ create_collection -------------------\n",
    "    def create_collection(\n",
    "        self,\n",
    "        collection_name: str,\n",
    "        dimension: int,  # å¯¹åº” Milvus çš„ dimensionï¼ˆå‘é‡ç»´åº¦ï¼‰\n",
    "        metric_type: str = \"IP\",  # å¯¹åº” Milvus çš„ metric_typeï¼ˆè·ç¦»è®¡ç®—æ–¹å¼ï¼‰\n",
    "        consistency_level: str = \"Strong\"  # Faiss æ— éœ€æ­¤é…ç½®ï¼Œä»…ä¿ç•™å‚æ•°å…¼å®¹\n",
    "    ):\n",
    "        # 1. å…ˆåˆ é™¤å·²å­˜åœ¨çš„é›†åˆï¼ˆä¿æŒå’Œ Milvus é€»è¾‘ä¸€è‡´ï¼‰\n",
    "        if self.has_collection(collection_name):\n",
    "            self.drop_collection(collection_name)\n",
    "        \n",
    "        # 2. æ ¹æ® metric_type åˆå§‹åŒ– Faiss ç´¢å¼•ï¼ˆæ ¸å¿ƒï¼šFaiss ç”¨ä¸åŒç´¢å¼•ç±»å¯¹åº”è·ç¦»ç±»å‹ï¼‰\n",
    "        if metric_type == \"IP\":\n",
    "            # IPï¼ˆå†…ç§¯ï¼‰ï¼šFaiss ç”¨ IndexFlatIP å®ç°å†…ç§¯è·ç¦»è®¡ç®—\n",
    "            self.index = faiss.IndexFlatIP(dimension)\n",
    "        elif metric_type == \"L2\":\n",
    "            # L2ï¼ˆæ¬§æ°è·ç¦»ï¼‰ï¼šFaiss ç”¨ IndexFlatL2 å®ç°ï¼Œå…¼å®¹ Milvus é»˜è®¤é€»è¾‘\n",
    "            self.index = faiss.IndexFlatL2(dimension)\n",
    "        else:\n",
    "            raise ValueError(f\"âŒ Faiss æš‚ä¸æ”¯æŒè¯¥ metric_typeï¼š{metric_type}ï¼Œä»…æ”¯æŒ 'IP' æˆ– 'L2'\")\n",
    "        \n",
    "        # 3. æ ‡è®°é›†åˆåˆ›å»ºæˆåŠŸï¼ˆFaiss æ— åˆ†å¸ƒå¼ç‰¹æ€§ï¼Œconsistency_level ä»…æ³¨é‡Šè¯´æ˜ï¼Œæ— éœ€å®é™…é…ç½®ï¼‰\n",
    "        self.collection_exists = True\n",
    "        print(f\"âœ… é›†åˆ {collection_name} åˆ›å»ºæˆåŠŸ\")\n",
    "        print(f\"  - å‘é‡ç»´åº¦ï¼š{dimension}\")\n",
    "        print(f\"  - è·ç¦»ç±»å‹ï¼š{metric_type}ï¼ˆå†…ç§¯ï¼‰\")\n",
    "        print(f\"  - è¯´æ˜ï¼šFaiss æœ¬åœ°ç´¢å¼•æ— éœ€ 'consistency_level' é…ç½®ï¼Œ{consistency_level} ä»…ä½œå…¼å®¹ä¿ç•™\")\n",
    "\n",
    "    def insert(self, vectors, texts):\n",
    "        if not self.collection_exists or self.index is None:\n",
    "            raise ValueError(\"âŒ è¯·å…ˆè°ƒç”¨ create_collection åˆ›å»ºé›†åˆå†æ’å…¥æ•°æ®ï¼\")\n",
    "        # Faiss è¦æ±‚å‘é‡ä¸º float32 ç±»å‹ï¼Œéœ€è½¬æ¢æ ¼å¼\n",
    "        vectors = np.array(vectors, dtype=np.float32)\n",
    "        self.index.add(vectors)  # æ’å…¥å‘é‡åˆ° Faiss ç´¢å¼•\n",
    "        self.vectors.extend(vectors)\n",
    "        self.texts.extend(texts)\n",
    "        print(f\"âœ… å‘é›†åˆ {collection_name} æ’å…¥ {len(vectors)} æ¡æ•°æ®æˆåŠŸ\")\n",
    "\n",
    "    def search(self, query_vector, top_k=3):\n",
    "        if not self.collection_exists or self.index is None:\n",
    "            raise ValueError(\"âŒ è¯·å…ˆè°ƒç”¨ create_collection åˆ›å»ºé›†åˆå†æ£€ç´¢æ•°æ®ï¼\")\n",
    "        query_vector = np.array([query_vector], dtype=np.float32)\n",
    "        distances, indices = self.index.search(query_vector, top_k)  # Faiss æ£€ç´¢\n",
    "        # æå–æ£€ç´¢ç»“æœå¯¹åº”çš„æ–‡æœ¬\n",
    "        similar_texts = [self.texts[i] for i in indices[0] if i < len(self.texts)]\n",
    "        return similar_texts\n",
    "\n",
    "\n",
    "# ------------------- æµ‹è¯•ï¼šå®Œå…¨å¤ç”¨ä½ åŸæœ¬çš„è°ƒç”¨æ ¼å¼ -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. åˆå§‹åŒ– Faiss å‘é‡å­˜å‚¨\n",
    "    vector_store = FaissVectorStore()\n",
    "    collection_name = \"my_rag_collection\"\n",
    "    embedding_dim = 768  # ç¤ºä¾‹ï¼šæ–‡æœ¬åµŒå…¥å¸¸ç”¨ç»´åº¦ï¼ˆå¦‚ BERT ç±»æ¨¡å‹è¾“å‡ºï¼‰\n",
    "\n",
    "    # 2. å®Œå…¨å¤ç”¨ä½ åŸæœ¬çš„ Milvus create_collection è°ƒç”¨æ ¼å¼ï¼\n",
    "    vector_store.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric_type=\"IP\",  # å†…ç§¯è·ç¦»ï¼Œå’Œ Milvus é…ç½®ä¸€è‡´\n",
    "        consistency_level=\"Strong\"  # ä¿ç•™å‚æ•°ï¼ŒFaiss æ— éœ€å®é™…é…ç½®\n",
    "    )\n",
    "\n",
    "    # 3. æ’å…¥ç¤ºä¾‹æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ–‡æœ¬åµŒå…¥åçš„å‘é‡ï¼‰\n",
    "    test_vectors = [np.random.random(embedding_dim).astype(\"float32\") for _ in range(5)]\n",
    "    test_texts = [f\"æ–‡æœ¬{i+1}ï¼šRAG ç¤ºä¾‹å†…å®¹\" for i in range(5)]\n",
    "    vector_store.insert(test_vectors, test_texts)\n",
    "\n",
    "    # 4. æ£€ç´¢ç¤ºä¾‹ï¼ˆæ¨¡æ‹Ÿé—®é¢˜åµŒå…¥å‘é‡ï¼‰\n",
    "    query_vector = np.random.random(embedding_dim).astype(\"float32\")\n",
    "    results = vector_store.search(query_vector, top_k=2)\n",
    "    print(f\"\\nğŸ“Š æ£€ç´¢åˆ°çš„ç›¸ä¼¼æ–‡æœ¬ï¼ˆtop 2ï¼‰ï¼š\")\n",
    "    for idx, text in enumerate(results, 1):\n",
    "        print(f\"{idx}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d5c538-9c13-4b8e-ad7a-d6f016c065aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 246723.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å‘é›†åˆ my_rag_collection æ’å…¥ 72 æ¡æ•°æ®æˆåŠŸ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np  # éœ€å¯¼å…¥numpyå¤„ç†å‘é‡æ ¼å¼\n",
    "\n",
    "# ------------------- 1. ç”Ÿæˆæ–‡æ¡£åµŒå…¥ï¼ˆä½ çš„åŸæœ‰ä»£ç ï¼Œæ— éœ€æ”¹ï¼‰ -------------------\n",
    "doc_embeddings = embedding_model.encode_documents(text_lines)  # å‡è®¾è¾“å‡ºæ˜¯ list æˆ– numpy æ•°ç»„\n",
    "\n",
    "# ------------------- 2. æ•°æ®æ ¼å¼è½¬æ¢ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šé€‚é… Faissï¼‰ -------------------\n",
    "data = []\n",
    "for i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n",
    "    data.append({\"id\": i, \"vector\": doc_embeddings[i], \"text\": line})\n",
    "\n",
    "# æ‹†è§£ä¸º Faiss éœ€è¦çš„ã€Œå‘é‡åˆ—è¡¨ã€å’Œã€Œæ–‡æœ¬åˆ—è¡¨ã€ï¼Œå¹¶è½¬æ¢å‘é‡ä¸º float32 ç±»å‹\n",
    "insert_vectors = []\n",
    "insert_texts = []\n",
    "for item in data:\n",
    "    # Faiss è¦æ±‚å‘é‡æ˜¯ float32 ç±»å‹çš„ numpy æ•°ç»„ï¼ˆé¿å…ç²¾åº¦é—®é¢˜ï¼‰\n",
    "    vec = np.array(item[\"vector\"], dtype=np.float32)\n",
    "    insert_vectors.append(vec)\n",
    "    insert_texts.append(item[\"text\"])\n",
    "\n",
    "# ------------------- 3. è°ƒç”¨ FaissVectorStore æ’å…¥æ•°æ®ï¼ˆä¿®æ”¹è°ƒç”¨æ–¹å¼ï¼‰ -------------------\n",
    "vector_store.insert(vectors=insert_vectors, texts=insert_texts)  # å¯¹åº”å°è£…çš„ insert æ–¹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1023b9-6d12-44c2-806e-1d0eb87bd70c",
   "metadata": {},
   "source": [
    "### æ„å»ºRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3196e7a-40f8-4f75-a898-53fd41e7b137",
   "metadata": {},
   "source": [
    "- ç¡®ä¿ FaissVectorStore ç±»å®šä¹‰æ­£ç¡®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babcd88a-a281-4312-99f2-645fab2cf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "class FaissVectorStore:\n",
    "    def __init__(self):\n",
    "        self.index = None\n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.collection_exists = False\n",
    "\n",
    "    def has_collection(self, collection_name):\n",
    "        return self.collection_exists\n",
    "\n",
    "    def drop_collection(self, collection_name):\n",
    "        if self.collection_exists:\n",
    "            self.index = None\n",
    "            self.vectors = []\n",
    "            self.texts = []\n",
    "            self.collection_exists = False\n",
    "            print(f\"ğŸ—‘ï¸  é›†åˆ {collection_name} å·²åˆ é™¤\")\n",
    "\n",
    "    def create_collection(\n",
    "        self,\n",
    "        collection_name: str,\n",
    "        dimension: int,\n",
    "        metric_type: str = \"IP\",\n",
    "        consistency_level: str = \"Strong\"\n",
    "    ):\n",
    "        if self.has_collection(collection_name):\n",
    "            self.drop_collection(collection_name)\n",
    "        \n",
    "        if metric_type == \"IP\":\n",
    "            self.index = faiss.IndexFlatIP(dimension)\n",
    "        elif metric_type == \"L2\":\n",
    "            self.index = faiss.IndexFlatL2(dimension)\n",
    "        else:\n",
    "            raise ValueError(f\"âŒ Faiss ä»…æ”¯æŒ 'IP'/'L2'ï¼Œä¸æ”¯æŒ {metric_type}\")\n",
    "        \n",
    "        self.collection_exists = True\n",
    "        print(f\"âœ… é›†åˆ {collection_name} åˆ›å»ºæˆåŠŸï¼ˆç»´åº¦ï¼š{dimension}ï¼Œè·ç¦»ï¼š{metric_type}ï¼‰\")\n",
    "\n",
    "    def insert(self, vectors, texts):\n",
    "        if not self.collection_exists or self.index is None:\n",
    "            raise ValueError(\"âŒ è¯·å…ˆåˆ›å»ºé›†åˆï¼\")\n",
    "        vectors = np.array(vectors, dtype=np.float32)\n",
    "        self.index.add(vectors)\n",
    "        self.vectors.extend(vectors)\n",
    "        self.texts.extend(texts)\n",
    "        print(f\"âœ… æ’å…¥ {len(vectors)} æ¡æ•°æ®æˆåŠŸ\")\n",
    "\n",
    "    def search(self, query_vector, top_k=3):\n",
    "        if not self.collection_exists or self.index is None:\n",
    "            raise ValueError(\"âŒ è¯·å…ˆåˆ›å»ºé›†åˆï¼\")\n",
    "        query_vector = np.array([query_vector], dtype=np.float32)\n",
    "        distances, indices = self.index.search(query_vector, top_k)\n",
    "        return [self.texts[i] for i in indices[0] if i < len(self.texts)]\n",
    "\n",
    "    def search_with_distance(self, query_vector, top_k=3):\n",
    "        if not self.collection_exists or self.index is None:\n",
    "            raise ValueError(\"âŒ è¯·å…ˆåˆ›å»ºé›†åˆå¹¶æ’å…¥æ•°æ®ï¼\")\n",
    "        \n",
    "        query_vector = np.array([query_vector], dtype=np.float32)\n",
    "        distances, indices = self.index.search(query_vector, top_k)\n",
    "        \n",
    "        similar_texts = []\n",
    "        valid_distances = []\n",
    "        for idx, dist in zip(indices[0], distances[0]):\n",
    "            if idx < len(self.texts):\n",
    "                similar_texts.append(self.texts[idx])\n",
    "                valid_distances.append(float(dist))\n",
    "        \n",
    "        return similar_texts, valid_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad0b72-a216-49c1-b163-f89a3c02c7ec",
   "metadata": {},
   "source": [
    "- æŒ‰é¡ºåºæ‰§è¡Œ â€œåˆå§‹åŒ–â†’åˆ›å»ºé›†åˆâ†’æ’å…¥æ•°æ®â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067193a4-9cf2-48cf-9f1e-9c59f3c78193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in e:\\anaconda\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.56.0)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in e:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in e:\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\anaconda\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8255c31b-03d0-468a-b7f5-99e68aa6752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é›†åˆ my_rag_collection åˆ›å»ºæˆåŠŸï¼ˆç»´åº¦ï¼š384ï¼Œè·ç¦»ï¼šIPï¼‰\n",
      "âœ… æ’å…¥ 3 æ¡æ•°æ®æˆåŠŸ\n"
     ]
    }
   ],
   "source": [
    "# ------------------- å¿…é¡»å…ˆæ‰§è¡Œçš„æ­¥éª¤ -------------------\n",
    "# 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨å®ä¾‹\n",
    "vector_store = FaissVectorStore()\n",
    "\n",
    "# 2. å®šä¹‰é›†åˆåç§°å’Œå‘é‡ç»´åº¦ï¼ˆç»´åº¦å¿…é¡»ä¸ä½ çš„åµŒå…¥æ¨¡å‹è¾“å‡ºä¸€è‡´ï¼‰\n",
    "collection_name = \"my_rag_collection\"\n",
    "embedding_dim = 384  # ç¤ºä¾‹ï¼šå¦‚æœç”¨ all-MiniLM-L6-v2 æ¨¡å‹ï¼Œç»´åº¦æ˜¯ 384\n",
    "\n",
    "# 3. åˆ›å»ºé›†åˆï¼ˆå¿…é¡»æ‰§è¡Œï¼ï¼‰\n",
    "vector_store.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=embedding_dim,\n",
    "    metric_type=\"IP\"  # å†…ç§¯è·ç¦»ï¼Œä¸æ£€ç´¢é€»è¾‘ä¸€è‡´\n",
    ")\n",
    "\n",
    "# 4. å‡†å¤‡ä½ çš„çŸ¥è¯†åº“æ•°æ®ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…æ–‡æœ¬ï¼‰\n",
    "text_lines = [\n",
    "    \"åˆ¤æ–­ Milvus æ˜¯å¦å¯åŠ¨æˆåŠŸçš„æ–¹æ³•ï¼š1. ç”¨ docker ps æŸ¥çœ‹å®¹å™¨çŠ¶æ€ä¸º Upï¼›2. æŸ¥çœ‹æ—¥å¿—æ˜¯å¦æœ‰ 'Milvus started successfully'ï¼›3. å®¢æˆ·ç«¯è¿æ¥æ— é”™è¯¯ã€‚\",\n",
    "    \"Milvus å¯åŠ¨å¤±è´¥å¸¸è§åŸå› ï¼šç«¯å£å ç”¨ã€å†…å­˜ä¸è¶³ã€é•œåƒç‰ˆæœ¬ä¸å…¼å®¹ã€‚\",\n",
    "    \"Milvus æ˜¯å¼€æºå‘é‡æ•°æ®åº“ï¼Œæ”¯æŒæµ·é‡å‘é‡å­˜å‚¨å’Œæ£€ç´¢ã€‚\"\n",
    "]\n",
    "\n",
    "# 5. ç”Ÿæˆæ–‡æ¡£åµŒå…¥å‘é‡ï¼ˆæ›¿æ¢ä¸ºä½ çš„åµŒå…¥æ¨¡å‹ï¼‰\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # ç¤ºä¾‹æ¨¡å‹\n",
    "doc_embeddings = embedding_model.encode(text_lines)  # ç”Ÿæˆå‘é‡\n",
    "\n",
    "# 6. æ’å…¥æ•°æ®åˆ° Faissï¼ˆå¿…é¡»æ‰§è¡Œï¼ï¼‰\n",
    "insert_vectors = [np.array(vec, dtype=np.float32) for vec in doc_embeddings]  # è½¬æ¢æ ¼å¼\n",
    "insert_texts = text_lines\n",
    "vector_store.insert(vectors=insert_vectors, texts=insert_texts)\n",
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ba8eb-51de-42b2-9cf7-f6b9d75918ae",
   "metadata": {},
   "source": [
    "- æ‰§è¡Œæ£€ç´¢ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa8844fa-5bd8-4a06-b1e1-bd7a84568d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    [\n",
      "        \"åˆ¤æ–­ Milvus æ˜¯å¦å¯åŠ¨æˆåŠŸçš„æ–¹æ³•ï¼š1. ç”¨ docker ps æŸ¥çœ‹å®¹å™¨çŠ¶æ€ä¸º Upï¼›2. æŸ¥çœ‹æ—¥å¿—æ˜¯å¦æœ‰ 'Milvus started successfully'ï¼›3. å®¢æˆ·ç«¯è¿æ¥æ— é”™è¯¯ã€‚\",\n",
      "        0.435508131980896\n",
      "    ],\n",
      "    [\n",
      "        \"Milvus æ˜¯å¼€æºå‘é‡æ•°æ®åº“ï¼Œæ”¯æŒæµ·é‡å‘é‡å­˜å‚¨å’Œæ£€ç´¢ã€‚\",\n",
      "        0.2982614040374756\n",
      "    ],\n",
      "    [\n",
      "        \"Milvus å¯åŠ¨å¤±è´¥å¸¸è§åŸå› ï¼šç«¯å£å ç”¨ã€å†…å­˜ä¸è¶³ã€é•œåƒç‰ˆæœ¬ä¸å…¼å®¹ã€‚\",\n",
      "        0.2323351502418518\n",
      "    ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 1. é—®é¢˜å®šä¹‰\n",
    "question = \"How do I know if Milvus has started successfully?\"\n",
    "\n",
    "# 2. ç”Ÿæˆé—®é¢˜åµŒå…¥å‘é‡ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šå°† encode_queries æ”¹ä¸º encodeï¼‰\n",
    "query_embedding = embedding_model.encode([question])[0]  # ç”¨ encode æ›¿ä»£ encode_queries\n",
    "\n",
    "# 3. Faissæ£€ç´¢\n",
    "top_k = 3\n",
    "similar_texts, distances = vector_store.search_with_distance(\n",
    "    query_vector=query_embedding, \n",
    "    top_k=top_k\n",
    ")\n",
    "\n",
    "# 4. æ•´ç†å¹¶æ‰“å°ç»“æœ\n",
    "import json\n",
    "retrieved_lines_with_distances = list(zip(similar_texts, distances))\n",
    "print(json.dumps(retrieved_lines_with_distances, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a7d81-9aac-4f6c-bdfe-521e03356a4d",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ LLM è·å– RAG å“åº”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a21008-5807-4cdd-825e-6d8ba3f7479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join(\n",
    "    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58227acf-ccda-4d06-933d-26c1e57a7143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"åˆ¤æ–­ Milvus æ˜¯å¦å¯åŠ¨æˆåŠŸçš„æ–¹æ³•ï¼š1. ç”¨ docker ps æŸ¥çœ‹å®¹å™¨çŠ¶æ€ä¸º Upï¼›2. æŸ¥çœ‹æ—¥å¿—æ˜¯å¦æœ‰ 'Milvus started successfully'ï¼›3. å®¢æˆ·ç«¯è¿æ¥æ— é”™è¯¯ã€‚\\nMilvus æ˜¯å¼€æºå‘é‡æ•°æ®åº“ï¼Œæ”¯æŒæµ·é‡å‘é‡å­˜å‚¨å’Œæ£€ç´¢ã€‚\\nMilvus å¯åŠ¨å¤±è´¥å¸¸è§åŸå› ï¼šç«¯å£å ç”¨ã€å†…å­˜ä¸è¶³ã€é•œåƒç‰ˆæœ¬ä¸å…¼å®¹ã€‚\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5edc9cfc-c9d4-4d73-a951-26adb4f607e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I know if Milvus has started successfully?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2db27460-a1d2-463f-afdb-5646cd8fd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ç³»ç»Ÿæç¤º\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢ä¿¡æ¯çš„é—®ç­”åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š\n",
    "1. ä»…ä½¿ç”¨<context>ä¸­æä¾›çš„ä¿¡æ¯å›ç­”<question>ä¸­çš„é—®é¢˜ï¼Œä¸å…è®¸ä½¿ç”¨å¤–éƒ¨çŸ¥è¯†ã€‚\n",
    "2. è‹¥ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œç›´æ¥è¯´æ˜\"æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜\"ã€‚\n",
    "3. å›ç­”éœ€ç®€æ´å‡†ç¡®ï¼Œç”¨è‹±æ–‡ç»„ç»‡è¯­è¨€ã€‚\n",
    "4. å®Œæˆè‹±æ–‡å›ç­”åï¼Œå¿…é¡»æä¾›ç²¾å‡†çš„ä¸­æ–‡ç¿»è¯‘ï¼Œæ”¾åœ¨<translated>æ ‡ç­¾å†…ã€‚\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = f\"\"\"\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "# ä»»åŠ¡è¦æ±‚ï¼š\n",
    "# 1. é¦–å…ˆï¼Œç”¨è‹±æ–‡å›ç­”<question>ä¸­çš„é—®é¢˜ï¼Œå›ç­”å¿…é¡»ä¸¥æ ¼åŸºäº<context>å†…çš„ä¿¡æ¯ï¼Œç¦æ­¢ç¼–é€ ã€‚\n",
    "# 2. å¦‚æœ<context>ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·ç›´æ¥è¾“å‡ºï¼š\"Based on the provided information, I can't answer this question.\"\n",
    "# 3. ç„¶åï¼Œåœ¨<translated></translated>æ ‡ç­¾å†…ï¼Œæä¾›ä¸Šè¿°è‹±æ–‡å›ç­”çš„ç²¾å‡†ä¸­æ–‡ç¿»è¯‘ã€‚\n",
    "# 4. è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š\n",
    "# [è‹±æ–‡å›ç­”]\n",
    "# <translated>\n",
    "# [ä¸­æ–‡ç¿»è¯‘]\n",
    "# </translated>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1a2ff5e-d17a-416b-908b-e6203ac05210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<context>\\nåˆ¤æ–­ Milvus æ˜¯å¦å¯åŠ¨æˆåŠŸçš„æ–¹æ³•ï¼š1. ç”¨ docker ps æŸ¥çœ‹å®¹å™¨çŠ¶æ€ä¸º Upï¼›2. æŸ¥çœ‹æ—¥å¿—æ˜¯å¦æœ‰ \\'Milvus started successfully\\'ï¼›3. å®¢æˆ·ç«¯è¿æ¥æ— é”™è¯¯ã€‚\\nMilvus æ˜¯å¼€æºå‘é‡æ•°æ®åº“ï¼Œæ”¯æŒæµ·é‡å‘é‡å­˜å‚¨å’Œæ£€ç´¢ã€‚\\nMilvus å¯åŠ¨å¤±è´¥å¸¸è§åŸå› ï¼šç«¯å£å ç”¨ã€å†…å­˜ä¸è¶³ã€é•œåƒç‰ˆæœ¬ä¸å…¼å®¹ã€‚\\n</context>\\n\\n<question>\\nHow do I know if Milvus has started successfully?\\n</question>\\n\\n# ä»»åŠ¡è¦æ±‚ï¼š\\n# 1. é¦–å…ˆï¼Œç”¨è‹±æ–‡å›ç­”<question>ä¸­çš„é—®é¢˜ï¼Œå›ç­”å¿…é¡»ä¸¥æ ¼åŸºäº<context>å†…çš„ä¿¡æ¯ï¼Œç¦æ­¢ç¼–é€ ã€‚\\n# 2. å¦‚æœ<context>ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·ç›´æ¥è¾“å‡ºï¼š\"Based on the provided information, I can\\'t answer this question.\"\\n# 3. ç„¶åï¼Œåœ¨<translated></translated>æ ‡ç­¾å†…ï¼Œæä¾›ä¸Šè¿°è‹±æ–‡å›ç­”çš„ç²¾å‡†ä¸­æ–‡ç¿»è¯‘ã€‚\\n# 4. è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š\\n# [è‹±æ–‡å›ç­”]\\n# <translated>\\n# [ä¸­æ–‡ç¿»è¯‘]\\n# </translated>\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f342a-1961-40d7-980b-ae82983b6a32",
   "metadata": {},
   "source": [
    "- ä½¿ç”¨ DeepSeek æä¾›çš„ deepseek-chat æ¨¡å‹æ ¹æ®æç¤ºç”Ÿæˆå“åº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfd683fe-7f1d-4be5-a34c-006bf84c5cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine if Milvus has started successfully: 1. Check that the container status is \"Up\" using `docker ps`; 2. Verify the logs for the message 'Milvus started successfully'; 3. Ensure the client connects without errors.\n",
      "<translated>\n",
      "è¦åˆ¤æ–­ Milvus æ˜¯å¦å¯åŠ¨æˆåŠŸï¼š1. ä½¿ç”¨ `docker ps` æŸ¥çœ‹å®¹å™¨çŠ¶æ€æ˜¯å¦ä¸º \"Up\"ï¼›2. æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦æœ‰ 'Milvus started successfully' æ¶ˆæ¯ï¼›3. ç¡®ä¿å®¢æˆ·ç«¯è¿æ¥æ— é”™è¯¯ã€‚\n",
      "</translated>\n"
     ]
    }
   ],
   "source": [
    "response = deepseek_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7950aa2-90d6-4d43-b805-09f6cf4fd39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
